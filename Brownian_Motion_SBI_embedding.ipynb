{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Necessary Libraries\n",
    "Imports required Python libraries for numerical computations, deep learning, and probabilistic modeling:\n",
    "\n",
    "- `numpy`, `torch`, and `numba` for numerical and tensor computations.\n",
    "- `matplotlib.pyplot` for visualization.\n",
    "- `sbi` (simulation-based inference) for probabilistic inference tasks. Here it is important to use `!pip install sbi==0.22.0` since newer `sbi` modules have a new syntax and will therefore not work.\n",
    "- Custom modules (`src.mamba`, `src.temporal_encoders`) for specific modeling purposes.\n",
    "\n",
    "### 2. Simulating Brownian Motion\n",
    "The function `simulate_brownian_motion` generates sample paths of a Brownian motion with drift and diffusion:\n",
    "- Uses an Euler-Maruyama scheme for stochastic differential equations.\n",
    "- Incorporates a restoring force parameter `k`.\n",
    "- Returns a tensor containing simulation results.\n",
    "\n",
    "### 3. Brownian Motion Simulators\n",
    "Several functions wrap `simulate_brownian_motion` to format the output differently for different neural network architectures:\n",
    "- `Brownian_Motion_simulator_SSM`, `Brownian_Motion_simulator_Transformer`, etc.\n",
    "- Each function modifies the output shape and resolution according to the respective modelâ€™s requirements.\n",
    "\n",
    "### 4. Neural Network Models\n",
    "The notebook implements various deep learning models for processing Brownian motion data:\n",
    "- **1D CNN (`ConvNet1D`)**: A convolutional neural network for temporal pattern extraction.\n",
    "- **Transformer (`TemporalTransformer`)**: Uses self-attention mechanisms for sequence modeling.\n",
    "- **SSM (`TemporalMamba`)**: A structured state-space model leveraging Mamba layers.\n",
    "- **Alternative CNN (`TemporalCNN`)**: Another CNN variant with optional attention mechanisms.\n",
    "\n",
    "### 5. Model Instantiation\n",
    "The last section initializes one of the models (SSM, CNN, Transformer, or 1D CNN). The selected model is assigned to the variable `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import einops\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src.mamba import Mamba, MambaConfig \n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from sbi.inference.base import infer\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi\n",
    "from sbi import analysis, utils\n",
    "from sbi.inference import SNPE, simulate_for_sbi\n",
    "from sbi.utils.user_input_checks import (\n",
    "    check_sbi_inputs,\n",
    "    process_prior,\n",
    "    process_simulator,\n",
    ")\n",
    "# import required modules\n",
    "from sbi.utils.get_nn_models import posterior_nn\n",
    "seed = 0 \n",
    "torch.manual_seed(seed) \n",
    "from src.temporal_encoders import ResidualTemporalBlock, Residual, PreNorm, LinearAttention, Downsample1d, Conv1dBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_brownian_motion(num_steps=1000, dt = 5e-06, replica_num=1, D=10, x0=np.array([-1.5], dtype=np.float64), save_every=1, k=3):\n",
    "    num_steps = int(num_steps)\n",
    "    save_every = int(save_every)\n",
    "    \n",
    "    N = num_steps\n",
    "\n",
    "    diffusion_coeffs = np.full(replica_num, D)\n",
    "    Ax = diffusion_coeffs * dt\n",
    "    Bx = np.sqrt(2 * Ax)\n",
    "    \n",
    "    x = np.zeros((num_steps//save_every, replica_num, 1), dtype=np.float64)\n",
    "    xold = np.tile(x0, (replica_num, 1))\n",
    "\n",
    "    for i in range(1, N):\n",
    "        # forces evaluation\n",
    "        Fx = -k * xold\n",
    "\n",
    "        # Drawing noise \n",
    "        gx = np.random.standard_normal(size=(replica_num, 1))\n",
    "\n",
    "        # integration\n",
    "        xnew = xold + Ax[:, None] * Fx + Bx[:, None] * gx\n",
    "\n",
    "        if (i % save_every) == 0:\n",
    "            x[i // save_every] = xnew\n",
    "\n",
    "        xold = xnew\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Brownian_Motion_simulator_SSM(params):\n",
    "    params = np.array(params.cpu(), dtype=np.float64)\n",
    "    x = simulate_brownian_motion(num_steps=1000, dt = 5e-06, replica_num=1, D=10**params[0], x0=np.array([-1.5], dtype=np.float64), save_every=1, k=3)\n",
    "    return torch.tensor(x, dtype=torch.float32)\n",
    "\n",
    "def Brownian_Motion_simulator_opt_CNN(params):\n",
    "    params = np.array(params.cpu(), dtype=np.float64)\n",
    "    x = simulate_brownian_motion(num_steps=5, dt=5e-06, replica_num=1, D=10**params[0], x0=np.array([-1.5], dtype=np.float64), save_every=1, k=3)\n",
    "    return torch.tensor(x, dtype=torch.float32)\n",
    "\n",
    "def Brownian_Motion_simulator_Transformer(params):\n",
    "    params = np.array(params.cpu(), dtype=np.float64)\n",
    "    x = simulate_brownian_motion(num_steps=1000, dt = 5e-06, replica_num=1, D=10**params[0], x0=np.array([-1.5], dtype=np.float64), save_every=1, k=3)\n",
    "    x = x.reshape(-1)\n",
    "    return torch.tensor(x, dtype=torch.float32)\n",
    "\n",
    "def Brownian_Motion_simulator_1D_CNN(params):\n",
    "    params = np.array(params.cpu(), dtype=np.float64)\n",
    "    x =  simulate_brownian_motion(num_steps=1000, dt = 5e-06, D=10**params[0], x0=np.array([-1.5], dtype=np.float64), save_every=1, k=3)\n",
    "    return torch.tensor(x, dtype=torch.float32).reshape(1, -1)\n",
    "\n",
    "def Brownian_Motion_simulator_noCNN(params):\n",
    "    params = np.array(params, dtype=np.float64)\n",
    "    positions =  simulate_brownian_motion(num_steps=1000, dt = 5e-06, replica_num=1, D=10**params[0], x0=np.array([-1.5], dtype=np.float64), save_every=1, k=3)\n",
    "    positions = positions.reshape(-1)\n",
    "    return torch.tensor(positions, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1D CNN\n",
    "class ConvNet1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 100, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.MaxPool1d(20),\n",
    "            )\n",
    "        self.layer2 = nn.Flatten(start_dim=1)\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(4900, 100),  \n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Linear(100,6),\n",
    "            nn.Softmax(dim=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.reshape(-1,1,1000)\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        return out\n",
    "\n",
    "#Transformer\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TemporalTransformer(nn.Module):\n",
    "    def __init__(self, transition_dim, dim=32, kernel_sizes=(4, 4), stride=2, num_heads=4, depth=4, mlp_dim=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=transition_dim if i == 0 else dim, out_channels=dim, \n",
    "                      kernel_size=ks, stride=stride, padding=ks//2)\n",
    "            for i, ks in enumerate(kernel_sizes)\n",
    "        ])\n",
    "\n",
    "        self.pos_embedding = PositionalEncoding(dim, dropout=0.1, max_len=5000)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        \n",
    "        transformer_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=dim, \n",
    "            nhead=num_heads, \n",
    "            dim_feedforward=mlp_dim,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(transformer_layer, num_layers=depth)\n",
    "\n",
    "        self.to_out = nn.Linear(dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            x : [ batch x horizon x transition ]\n",
    "        '''\n",
    "        \n",
    "        x=x.unsqueeze(2)\n",
    "        \n",
    "        x = einops.rearrange(x, 'b h t -> b t h')\n",
    "\n",
    "        for conv in self.conv_layers:\n",
    "            x = F.relu(conv(x))\n",
    "\n",
    "        x = einops.rearrange(x, 'b t h -> b h t')\n",
    "        x = self.pos_embedding(x)\n",
    "\n",
    "        cls_tokens = self.cls_token.expand(x.shape[0], -1, -1) \n",
    "        x = torch.cat((cls_tokens, x), dim=1)  # Shape: [batch, horizon + 1, dim]\n",
    "        \n",
    "        x = self.transformer(x)  \n",
    "\n",
    "        x = x[:, 0]\n",
    "        x = self.to_out(x)\n",
    "        return x\n",
    "\n",
    "#Optional Attention\n",
    "class TemporalCNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        transition_dim,\n",
    "        dim=32,\n",
    "        dim_mults=(1, 2, 4),\n",
    "        attention=True,\n",
    "        padding_mode='reflect',\n",
    "        kernel_size=3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]\n",
    "        in_out = list(zip(dims[:-1], dims[1:]))\n",
    "        print(f'[ models/temporal ] Channel dimensions: {dims}')\n",
    "\n",
    "        self.downs = nn.ModuleList([])\n",
    "        self.ups = nn.ModuleList([])\n",
    "        num_resolutions = len(in_out)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.downs.append(nn.ModuleList([\n",
    "                ResidualTemporalBlock(dim_in, dim_out, kernel_size = kernel_size, padding_mode=padding_mode),\n",
    "                ResidualTemporalBlock(dim_out, dim_out, kernel_size = kernel_size, padding_mode=padding_mode),\n",
    "                Residual(PreNorm(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),\n",
    "                Downsample1d(dim_out) if not is_last else nn.Identity()\n",
    "            ]))\n",
    "\n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, kernel_size = kernel_size, padding_mode=padding_mode)\n",
    "        self.mid_attn = Residual(PreNorm(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()\n",
    "        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, kernel_size = kernel_size, padding_mode=padding_mode)\n",
    "\n",
    "        self.proj_out = nn.Linear(mid_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            x : [ batch x horizon x transition ]\n",
    "        '''\n",
    "\n",
    "        #reshape to [batch x transition x horizon]\n",
    "\n",
    "        x = x.squeeze(-1)\n",
    "        \n",
    "        x = einops.rearrange(x, 'b h t -> b t h')\n",
    "     \n",
    "        \n",
    "        for resnet, resnet2, attn, downsample in self.downs:\n",
    "            x = resnet(x)\n",
    "            x = resnet2(x)\n",
    "            x = attn(x)\n",
    "            x = downsample(x)\n",
    "\n",
    "        x = self.mid_block1(x)\n",
    "        x = self.mid_attn(x)\n",
    "        x = self.mid_block2(x)\n",
    "        x = x.mean(dim=-1)\n",
    "        x = self.proj_out(x)\n",
    "        return x\n",
    "\n",
    "#SSM\n",
    "class TemporalMamba(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        transition_dim,\n",
    "        dim=128,\n",
    "        kernel_size=3,\n",
    "        expand=2,\n",
    "        num_layers=1, \n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mamba_layers = nn.ModuleList() #layer mamba\n",
    "        self.l_norm_layers = nn.ModuleList() #layer norm\n",
    "\n",
    "        for _ in range(num_layers):\n",
    "            config = MambaConfig(n_layers=num_layers, d_model=dim, d_state=dim, d_conv=kernel_size, expand_factor=expand)\n",
    "            self.mamba_layers.append(Mamba(config))\n",
    "        \n",
    "            self.l_norm_layers.append(nn.LayerNorm(dim))\n",
    "        \n",
    "        self.x_emb = nn.Linear(transition_dim, dim) #layer embedding\n",
    "        self.proj_out = nn.Linear(dim, 1) #layer output\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            x : [ batch x horizon x transition ]\n",
    "        '''\n",
    "        x = x.squeeze(-1)\n",
    "        x = self.x_emb(x)  \n",
    "        for mamba, l_norm in zip(self.mamba_layers, self.l_norm_layers):\n",
    "            x_in = x\n",
    "            x = mamba(x)\n",
    "            x = l_norm(x + x_in)\n",
    "        x = x[:, -1]\n",
    "        x = self.proj_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TemporalMamba(transition_dim=1, dim=32, kernel_size=3, expand=2, num_layers=2) #SSM\n",
    "#model = TemporalCNN(1, dim=32, dim_mults=(1, 2, 4), attention=True, padding_mode='reflect', kernel_size=1) #Opt CNN\n",
    "#model = TemporalTransformer(transition_dim=1, dim=32, kernel_sizes=(4, 4), stride=2, num_heads=4, depth=4, mlp_dim=32) # Transformer \n",
    "#model = ConvNet1D() #1DCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_limit = [-1]\n",
    "high_limit = [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = utils.BoxUniform(\n",
    "    low = torch.tensor([low_limit[0]], device='cuda'),\n",
    "    high = torch.tensor([high_limit[0]], device='cuda')\n",
    ")\n",
    "\n",
    "\n",
    "prior, num_parameters, prior_returns_numpy= process_prior(prior)\n",
    "\n",
    "simulator_wrapper = process_simulator(Brownian_Motion_simulator_SSM, prior, prior_returns_numpy)\n",
    "\n",
    "check_sbi_inputs(simulator_wrapper, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brownian_Motion_simulator, prior = prepare_for_sbi(Brownian_Motion_simulator_SSM, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_posterior = posterior_nn(model='nsf', embedding_net = model)\n",
    "\n",
    "inference = SNPE(prior, device = 'cuda', density_estimator=neural_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the inference procedure on one round and 10000 simulated data points\n",
    "theta, x = simulate_for_sbi(simulator_wrapper, prior, num_simulations=50000, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_estimator = inference.append_simulations(theta, x, data_device='cuda').train(training_batch_size=128, show_train_summary=True)\n",
    "\n",
    "posterior = inference.build_posterior(density_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('your_path.pkl', 'rb') as f:\n",
    "    posterior = torch.save(f) #save the posterior for later use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
